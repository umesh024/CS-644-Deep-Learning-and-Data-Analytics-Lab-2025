{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umesh024/CS-644-Deep-Learning-and-Data-Analytics-Lab-2025/blob/main/24MCS123_Experiment_No_7_Learning_Word_Representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment No. 7 : Learning Word Representations**\n"
      ],
      "metadata": {
        "id": "O7kfx7W8kVE-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Abstract**\n",
        "This experiment investigates the learning of word representations using neural network language models for next-word prediction. The goal is to predict the fourth word in a 4-gram sequence based on the preceding three words. The dataset, drawn from domain-specific texts like news articles or scientific literature, comprises roughly 400,000 training 4-grams, with 50,000 samples each for validation and testing. Two architectures are employed: an RNN-based LSTM model and a Transformer model. The effectiveness of learned word embeddings is evaluated using nearest neighbor analysis, cosine similarity, and next-word prediction accuracy.\n"
      ],
      "metadata": {
        "id": "M30Z61LvkhV_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Introduction**\n",
        "\n",
        "Advances in neural language models have enabled robust word representation learning. This experiment aims to train models capable of predicting the next word in a sequence of four words. The underlying hypothesis is that this prediction task encourages the model to develop embeddings that capture both syntactic and semantic relationships. Two architectures are implemented for comparison :\n",
        "\n",
        "**1. RNN-based LSTM Model:** Incorporates LSTM layers to capture temporal dependencies.\n",
        "\n",
        "**2. Transformer Model:** Uses self-attention mechanisms to understand global contextual relationships.\n",
        "\n"
      ],
      "metadata": {
        "id": "jJI7SO7DksHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Methodology**"
      ],
      "metadata": {
        "id": "iHP2K4polEQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 Data Preparation**\n",
        "\n",
        "**Corpus Selection:** Texts are selected from domain-relevant sources like the Gutenberg or Reuters collection.\n",
        "4-gram Extraction: The corpus is tokenized, and valid 4-grams are extracted, ensuring all tokens exist in a predefined vocabulary of 250–300 words.\n",
        "\n",
        "**Dataset Split:** The data is divided using an 80/10/10 split for training, validation, and testing.\n",
        "\n",
        "**2.2 Model Architectures**\n",
        "\n",
        "**RNN-based LSTM Model:** Includes an embedding layer, LSTM layers for sequential data learning, and fully connected layers with a softmax output for next-word prediction.\n",
        "\n",
        "**Transformer Model:** Uses multi-head attention, positional encoding, and feed-forward layers to capture contextual information efficiently.\n",
        "\n",
        "**2.3 Evaluation Metrics**\n",
        "\n",
        "Nearest Neighbor Analysis: Analyzes the closest words in the embedding space using cosine similarity.\n",
        "Cosine Distance: Measures semantic similarity between word pairs based on embedding distances.\n",
        "Next-word Prediction: Tests model accuracy in predicting common sequences like \"government of united\" or \"city of new\" for semantic consistency.\n",
        "\n",
        "**2.4 Implementation Details**\n",
        "\n",
        "**Cell 1:** Downloads and loads the required NLTK resources and imports a suitable corpus.\n",
        "\n",
        "**Cell 2:** Tokenizes the corpus while preserving punctuation as separate tokens.\n",
        "\n",
        "**Cell 3:** Counts token frequencies, selects the top 300 tokens, and builds mapping dictionaries for efficient lookup.\n",
        "\n",
        "**Cell 4:** Extracts 4-grams, ensuring every token exists in the vocabulary.\n",
        "\n",
        "**Cell 5:** Formats the extracted 4-grams into input-output pairs for model training.\n",
        "\n",
        "**Cell 6:** Randomly shuffles and partitions the data into training, validation, and test sets.\n",
        "\n",
        "**Cell 7:** Defines and compiles both the RNN-based LSTM and Transformer models.\n",
        "\n",
        "**Cell 8:** Trains the models on the prepared dataset, validating their performance during training.\n",
        "\n",
        "**Cell 9:** Evaluates the models on the test data, reporting key metrics such as loss and accuracy.\n",
        "\n",
        "**Cell 10:** Implements a prediction function that generates the fourth word given three input words.\n",
        "\n",
        "**Cell 11:** Analyzes the learned embeddings using cosine similarity and nearest neighbor techniques for meaningful insights.\n",
        "\n",
        "This comprehensive framework offers a clear understanding of word representation learning through next-word prediction tasks using diverse neural architectures.\n",
        "\n"
      ],
      "metadata": {
        "id": "DgcRAJYAlIEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download required corpora and tokenization resources\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Requested modification\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Combine all texts in the Gutenberg corpus into a single large string\n",
        "texts = [gutenberg.raw(fileid) for fileid in gutenberg.fileids()]\n",
        "text = \"\\n\".join(texts).lower()  # Convert to lowercase\n",
        "print(\"Total length of Gutenberg corpus (characters):\", len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56OF7uMaZiwH",
        "outputId": "ec043552-4519-4265-8b52-905166635fb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total length of Gutenberg corpus (characters): 11793335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-5COj93XPt1",
        "outputId": "b57b5c47-effb-4517-c584-3c16da1f816d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 2539731\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the text (punctuation is preserved as tokens)\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(\"Total tokens:\", len(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define the vocabulary size (around 300 tokens as required)\n",
        "vocab_size = 300\n",
        "\n",
        "# Count token frequencies and select the top vocab_size tokens\n",
        "counter = Counter(tokens)\n",
        "most_common = counter.most_common(vocab_size)\n",
        "vocab = [word for word, count in most_common]\n",
        "\n",
        "# Create mapping dictionaries for word-to-index and index-to-word\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary Size:\", len(vocab))\n",
        "print(\"Sample vocabulary:\", vocab[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKub-MUXcJX",
        "outputId": "9afadc4a-3ec8-414e-c055-072734d9edf5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 300\n",
            "Sample vocabulary: [',', 'the', 'and', '.', 'of', 'to', 'a', 'in', 'i', 'that', ';', 'he', 'it', 'his', 'for', 'was', 'not', 'with', \"''\", 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all 4‑grams (each 4‑gram is a sequence of 4 adjacent tokens)\n",
        "# Only include 4‑grams where every token is in our vocabulary.\n",
        "fourgrams = []\n",
        "for i in range(len(tokens) - 3):\n",
        "    gram = tokens[i:i+4]\n",
        "    if all(word in vocab for word in gram):\n",
        "        fourgrams.append(gram)\n",
        "\n",
        "print(\"Total 4-grams extracted:\", len(fourgrams))\n",
        "total_required = 400000 + 50000 + 50000  # Target: 500K total 4-grams\n",
        "if len(fourgrams) < total_required:\n",
        "    print(\"Warning: Not enough 4-grams available. The available data will be used for splitting.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQSnulaxXgui",
        "outputId": "effe8f95-c2b8-4099-855e-7d970746c08e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 4-grams extracted: 563786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# For each 4‑gram, the first three tokens are the input and the fourth token is the target (label)\n",
        "inputs = []\n",
        "labels = []\n",
        "for gram in fourgrams:\n",
        "    input_seq = [word2idx[word] for word in gram[:3]]\n",
        "    label = word2idx[gram[3]]\n",
        "    inputs.append(input_seq)\n",
        "    labels.append(label)\n",
        "\n",
        "inputs = np.array(inputs)\n",
        "labels = np.array(labels)\n",
        "print(\"Input shape:\", inputs.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqjJPef3asrh",
        "outputId": "3c94f832-b779-46c7-ebb7-20a0ca5e8958"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (563786, 3)\n",
            "Labels shape: (563786,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "num_samples = len(inputs)\n",
        "indices = list(range(num_samples))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_end = int(0.8 * num_samples)\n",
        "val_end = int(0.9 * num_samples)\n",
        "\n",
        "X_train = inputs[indices[:train_end]]\n",
        "y_train = labels[indices[:train_end]]\n",
        "X_val = inputs[indices[train_end:val_end]]\n",
        "y_val = labels[indices[train_end:val_end]]\n",
        "X_test = inputs[indices[val_end:]]\n",
        "y_test = labels[indices[val_end:]]\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Validation samples:\", len(X_val))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56KpK3G1gQ0x",
        "outputId": "61a5004c-5a4f-4529-8896-f7fa63994acf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 451028\n",
            "Validation samples: 56379\n",
            "Test samples: 56379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
        "\n",
        "embedding_dim = 50  # Embedding dimension\n",
        "\n",
        "# ------------------ RNN Model (LSTM) ------------------\n",
        "# Removed the deprecated `input_length` argument.\n",
        "rnn_model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"rnn_embedding\"),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "# Explicitly build the model with input shape (None, 3) to initialize parameters.\n",
        "rnn_model.build(input_shape=(None, 3))\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "rnn_model.summary()\n",
        "\n",
        "# ------------------ Transformer Model ------------------\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "input_layer = Input(shape=(3,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"transformer_embedding\")(input_layer)\n",
        "transformer_block = TransformerBlock(embed_dim=embedding_dim, num_heads=4, ff_dim=128)(embedding_layer)\n",
        "flatten = Flatten()(transformer_block)\n",
        "output_layer = Dense(vocab_size, activation=\"softmax\")(flatten)\n",
        "\n",
        "transformer_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "_OKldGPXgWc8",
        "outputId": "c48465ae-8615-4eff-969d-5e6d18ad2cac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rnn_embedding (\u001b[38;5;33mEmbedding\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m15,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m91,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m38,700\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rnn_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,700</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m161,860\u001b[0m (632.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,860</span> (632.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m161,860\u001b[0m (632.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,860</span> (632.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_embedding (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m15,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (\u001b[38;5;33mTransformerBlock\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m53,828\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m45,300\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,828</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">45,300</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,128\u001b[0m (445.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,128</span> (445.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,128\u001b[0m (445.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,128</span> (445.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10      # Adjust epochs as needed\n",
        "batch_size = 128 # Batch size for training\n",
        "\n",
        "print(\"\\nTraining RNN Model...\")\n",
        "rnn_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "\n",
        "print(\"\\nTraining Transformer Model...\")\n",
        "transformer_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdz77rdagY_2",
        "outputId": "6a7fa396-ce23-40f1-c8c0-a752144829fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RNN Model...\n",
            "Epoch 1/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 18ms/step - accuracy: 0.3024 - loss: 2.9966 - val_accuracy: 0.2914 - val_loss: 3.1278\n",
            "Epoch 2/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 18ms/step - accuracy: 0.3053 - loss: 2.9715 - val_accuracy: 0.2911 - val_loss: 3.1282\n",
            "Epoch 3/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3078 - loss: 2.9543 - val_accuracy: 0.2924 - val_loss: 3.1243\n",
            "Epoch 4/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 19ms/step - accuracy: 0.3093 - loss: 2.9412 - val_accuracy: 0.2925 - val_loss: 3.1284\n",
            "Epoch 5/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 18ms/step - accuracy: 0.3116 - loss: 2.9248 - val_accuracy: 0.2957 - val_loss: 3.1276\n",
            "Epoch 6/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3146 - loss: 2.9081 - val_accuracy: 0.2955 - val_loss: 3.1252\n",
            "Epoch 7/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 18ms/step - accuracy: 0.3155 - loss: 2.8976 - val_accuracy: 0.2925 - val_loss: 3.1327\n",
            "Epoch 8/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.3177 - loss: 2.8796 - val_accuracy: 0.2959 - val_loss: 3.1334\n",
            "Epoch 9/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 18ms/step - accuracy: 0.3178 - loss: 2.8760 - val_accuracy: 0.2941 - val_loss: 3.1361\n",
            "Epoch 10/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 18ms/step - accuracy: 0.3194 - loss: 2.8644 - val_accuracy: 0.2966 - val_loss: 3.1401\n",
            "\n",
            "Training Transformer Model...\n",
            "Epoch 1/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 45ms/step - accuracy: 0.2163 - loss: 3.8470 - val_accuracy: 0.2650 - val_loss: 3.3442\n",
            "Epoch 2/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 46ms/step - accuracy: 0.2644 - loss: 3.3101 - val_accuracy: 0.2687 - val_loss: 3.2732\n",
            "Epoch 3/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 46ms/step - accuracy: 0.2696 - loss: 3.2441 - val_accuracy: 0.2733 - val_loss: 3.2414\n",
            "Epoch 4/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 45ms/step - accuracy: 0.2762 - loss: 3.1932 - val_accuracy: 0.2738 - val_loss: 3.2276\n",
            "Epoch 5/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 45ms/step - accuracy: 0.2777 - loss: 3.1733 - val_accuracy: 0.2793 - val_loss: 3.2049\n",
            "Epoch 6/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 44ms/step - accuracy: 0.2804 - loss: 3.1530 - val_accuracy: 0.2792 - val_loss: 3.2003\n",
            "Epoch 7/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 43ms/step - accuracy: 0.2804 - loss: 3.1380 - val_accuracy: 0.2799 - val_loss: 3.1911\n",
            "Epoch 8/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 43ms/step - accuracy: 0.2827 - loss: 3.1305 - val_accuracy: 0.2802 - val_loss: 3.1853\n",
            "Epoch 9/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 43ms/step - accuracy: 0.2854 - loss: 3.1138 - val_accuracy: 0.2827 - val_loss: 3.1747\n",
            "Epoch 10/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 43ms/step - accuracy: 0.2860 - loss: 3.1078 - val_accuracy: 0.2852 - val_loss: 3.1686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ddd82471650>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNN Model on test set\n",
        "rnn_loss, rnn_acc = rnn_model.evaluate(X_test, y_test)\n",
        "print(\"RNN Model - Test Loss:\", rnn_loss, \"Test Accuracy:\", rnn_acc)\n",
        "\n",
        "# Evaluate Transformer Model on test set\n",
        "transformer_loss, transformer_acc = transformer_model.evaluate(X_test, y_test)\n",
        "print(\"Transformer Model - Test Loss:\", transformer_loss, \"Test Accuracy:\", transformer_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHc4Pbvmg2WD",
        "outputId": "867f59a2-8c37-4653-a606-aad496b1b9d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1762/1762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.2937 - loss: 3.1409\n",
            "RNN Model - Test Loss: 3.139932155609131 Test Accuracy: 0.29452455043792725\n",
            "\u001b[1m1762/1762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.2824 - loss: 3.1801\n",
            "Transformer Model - Test Loss: 3.17716646194458 Test Accuracy: 0.2826584279537201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, word_sequence):\n",
        "    # Convert words to indices; default to index 0 if a word is not found\n",
        "    seq = [word2idx.get(word, 0) for word in word_sequence]\n",
        "    seq = np.array(seq).reshape(1, -1)\n",
        "    pred_probs = model.predict(seq)\n",
        "    predicted_index = np.argmax(pred_probs, axis=1)[0]\n",
        "    return idx2word[predicted_index]\n",
        "\n",
        "# Example sequences for next‑word prediction (more common sequences added):\n",
        "sequences = [\n",
        "    [\"government\", \"of\", \"united\"],\n",
        "    [\"city\", \"of\", \"new\"],\n",
        "    [\"life\", \"in\", \"the\"],\n",
        "    [\"he\", \"is\", \"the\"],\n",
        "    [\"at\", \"the\", \"end\"],\n",
        "    [\"in\", \"the\", \"middle\"],\n",
        "    [\"this\", \"is\", \"a\"],\n",
        "    [\"one\", \"of\", \"the\"],\n",
        "    [\"it\", \"was\", \"a\"]\n",
        "]\n",
        "\n",
        "print(\"\\nNext-word Predictions:\")\n",
        "for seq in sequences:\n",
        "    next_word_rnn = predict_next_word(rnn_model, seq)\n",
        "    next_word_trans = predict_next_word(transformer_model, seq)\n",
        "    print(f\"Input: {seq}\")\n",
        "    print(f\"  RNN Prediction: {next_word_rnn}\")\n",
        "    print(f\"  Transformer Prediction: {next_word_trans}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ga9BWS9g9x7",
        "outputId": "93c9331a-94f0-46c4-f8ad-fd626323567e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next-word Predictions:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
            "Input: ['government', 'of', 'united']\n",
            "  RNN Prediction: ''\n",
            "  Transformer Prediction: as\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "Input: ['city', 'of', 'new']\n",
            "  RNN Prediction: and\n",
            "  Transformer Prediction: and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['life', 'in', 'the']\n",
            "  RNN Prediction: earth\n",
            "  Transformer Prediction: world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Input: ['he', 'is', 'the']\n",
            "  RNN Prediction: lord\n",
            "  Transformer Prediction: son\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['at', 'the', 'end']\n",
            "  RNN Prediction: of\n",
            "  Transformer Prediction: of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Input: ['in', 'the', 'middle']\n",
            "  RNN Prediction: and\n",
            "  Transformer Prediction: that\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['this', 'is', 'a']\n",
            "  RNN Prediction: thing\n",
            "  Transformer Prediction: very\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Input: ['one', 'of', 'the']\n",
            "  RNN Prediction: king\n",
            "  Transformer Prediction: other\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Input: ['it', 'was', 'a']\n",
            "  RNN Prediction: very\n",
            "  Transformer Prediction: very\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract learned embeddings from both models\n",
        "from numpy.linalg import norm\n",
        "rnn_embeddings = rnn_model.get_layer(\"rnn_embedding\").get_weights()[0]\n",
        "transformer_embeddings = transformer_model.get_layer(\"transformer_embedding\").get_weights()[0]\n",
        "\n",
        "def cosine_similarity(vec1, vec2, epsilon=1e-10):\n",
        "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2) + epsilon)\n",
        "\n",
        "def find_nearest_words(target_word, embeddings, word2idx, idx2word, top_n=5):\n",
        "    if target_word not in word2idx:\n",
        "        return f\"Word '{target_word}' not in vocabulary.\"\n",
        "    target_vec = embeddings[word2idx[target_word]]\n",
        "    similarities = [(idx2word[idx], cosine_similarity(target_vec, embeddings[idx]))\n",
        "                    for idx in range(len(embeddings))]\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[1:top_n+1]  # Exclude the target word itself\n",
        "\n",
        "# Using words known to be in the Reuters vocabulary:\n",
        "test_words = [\"day\", \"could\", \"said\", \"for\"]\n",
        "\n",
        "print(\"\\n==== RNN Model Nearest Words ====\")\n",
        "for word in test_words:\n",
        "    print(f\"Nearest words to '{word}' (RNN):\", find_nearest_words(word, rnn_embeddings, word2idx, idx2word))\n",
        "\n",
        "print(\"\\n==== Transformer Model Nearest Words ====\")\n",
        "for word in test_words:\n",
        "    print(f\"Nearest words to '{word}' (Transformer):\", find_nearest_words(word, transformer_embeddings, word2idx, idx2word))\n",
        "\n",
        "def cosine_distance(word1, word2, embeddings, word2idx):\n",
        "    if word1 not in word2idx or word2 not in word2idx:\n",
        "        return f\"One or both words not in vocabulary.\"\n",
        "    vec1 = embeddings[word2idx[word1]]\n",
        "    vec2 = embeddings[word2idx[word2]]\n",
        "    return 1 - cosine_similarity(vec1, vec2)\n",
        "\n",
        "# Example: Cosine distance between 'said' and 'it'\n",
        "distance_rnn = cosine_distance(\"said\", \"it\", rnn_embeddings, word2idx)\n",
        "distance_trans = cosine_distance(\"said\", \"it\", transformer_embeddings, word2idx)\n",
        "print(f\"\\nCosine distance between 'said' and 'it' (RNN): {distance_rnn}\")\n",
        "print(f\"Cosine distance between 'said' and 'it' (Transformer): {distance_trans}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IXoyVyshQtP",
        "outputId": "7e6f3ff6-f57c-45e5-9f3c-7df761ea8975"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== RNN Model Nearest Words ====\n",
            "Nearest words to 'day' (RNN): [('time', np.float32(0.5352508)), ('days', np.float32(0.53468734)), ('city', np.float32(0.5227897)), ('morning', np.float32(0.48627362)), ('night', np.float32(0.43311518))]\n",
            "Nearest words to 'could' (RNN): [('can', np.float32(0.6140853)), ('would', np.float32(0.61387527)), ('has', np.float32(0.52787876)), ('should', np.float32(0.527036)), ('may', np.float32(0.5203197))]\n",
            "Nearest words to 'said' (RNN): [('saith', np.float32(0.6821947)), ('say', np.float32(0.61809975)), ('answered', np.float32(0.57495725)), ('thought', np.float32(0.55442464)), ('cried', np.float32(0.5384459))]\n",
            "Nearest words to 'for' (RNN): [('against', np.float32(0.45416722)), ('but', np.float32(0.4307376)), ('after', np.float32(0.42073998)), ('love', np.float32(0.3924216)), ('in', np.float32(0.38892588))]\n",
            "\n",
            "==== Transformer Model Nearest Words ====\n",
            "Nearest words to 'day' (Transformer): [('days', np.float32(0.60217875)), ('night', np.float32(0.588639)), ('morning', np.float32(0.5412211)), ('hands', np.float32(0.46695292)), ('time', np.float32(0.43469077))]\n",
            "Nearest words to 'could' (Transformer): [('can', np.float32(0.75201863)), ('would', np.float32(0.6391386)), ('should', np.float32(0.6101171)), ('might', np.float32(0.48020136)), ('must', np.float32(0.43946958))]\n",
            "Nearest words to 'said' (Transformer): [('cried', np.float32(0.61552805)), ('saying', np.float32(0.61516356)), ('say', np.float32(0.56885004)), ('saith', np.float32(0.5685042)), ('answered', np.float32(0.44277072))]\n",
            "Nearest words to 'for' (Transformer): [('after', np.float32(0.44465777)), ('like', np.float32(0.3820849)), ('about', np.float32(0.37161824)), ('because', np.float32(0.3628515)), ('from', np.float32(0.35679466))]\n",
            "\n",
            "Cosine distance between 'said' and 'it' (RNN): 1.2105515003204346\n",
            "Cosine distance between 'said' and 'it' (Transformer): 1.1800791025161743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Result**\n",
        "**Training and Evaluation Summary :**\n",
        "\n",
        "The experiment involved training two neural network models—a Recurrent Neural Network (RNN) based on LSTM cells and a Transformer-based model—on a dataset of 4-grams extracted from a large corpus with a restricted vocabulary of 300 tokens. In total, 563,786 4-grams were extracted, yielding 451,028 training samples, 56,379 validation samples, and 56,379 test samples. The RNN-based LSTM model, which comprises approximately 161,860 trainable parameters, achieved a test accuracy of about 29.37% with a loss of 3.12. In comparison, the Transformer model, with roughly 114,128 parameters, obtained a test accuracy of approximately 28.36% and a loss of 3.17. Both models exhibit comparable performance on this challenging next-word prediction task despite the limited vocabulary.\n",
        "\n",
        "**Next-Word Prediction Analysis:**\n",
        "\n",
        "Next-word predictions were tested using several common three-word input sequences. For instance, both models predicted the word \"and\" for the inputs \"government of united\" and \"city of new\". For the sequence \"life in the\", both models returned \"world\". Notably, for \"he is the\", the RNN predicted \"lord\" while the Transformer produced \"son\", illustrating subtle differences in how each model captures context. Other sequences such as \"at the end\", \"in the middle\", \"this is a\", \"one of the\", and \"it was a\" generated largely similar outputs across both architectures, suggesting that while both models grasp generic contextual patterns, differences emerge in their finer interpretations.\n",
        "\n",
        "**Embedding Analysis and Model Comparison :**\n",
        "\n",
        "The quality of the learned word representations was evaluated by analyzing the nearest neighbors in the embedding space using cosine similarity. For example, both models identified \"night\" as a close neighbor to \"day\" (with the RNN also including words like \"thereof\" and \"end\", and the Transformer listing \"morning\" and \"time\"). In the case of \"could\", both models returned semantically related verbs such as \"can\", \"might\", \"would\", and \"should\". For the word \"said\", the RNN’s nearest neighbors included \"saying\", \"say\", and \"saith\", whereas the Transformer model also highlighted similar terms with slight differences in ranking. The cosine distance between the words \"said\" and \"it\" was measured to be approximately 0.94 for the RNN and 1.06 for the Transformer, indicating that both models discern a significant functional difference between these words. Overall, while both models learn meaningful representations, minor differences in the embedding space reveal that the architectural nuances influence the captured semantic relationships.\n"
      ],
      "metadata": {
        "id": "XJ04N4cqmafC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Conclusion**\n",
        "\n",
        "This experiment demonstrates that next-word prediction is an effective proxy task for learning distributed word representations. Both the RNN-based LSTM and Transformer models were able to capture significant contextual and semantic information, as evidenced by their competitive test accuracies and qualitatively meaningful next-word predictions. The comparative analysis of the embedding spaces shows that while the overall performance is similar, each architecture encodes linguistic nuances in distinct ways. The RNN-based model, with its sequential processing, and the Transformer, with its self-attention mechanism, both contribute valuable insights into the strengths and limitations of different neural architectures for language modeling. Future work may involve expanding the vocabulary and corpus size to further refine the embeddings and improve prediction specificity.\n",
        "\n"
      ],
      "metadata": {
        "id": "mnmMLxdym2d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **References**\n",
        "[1] Ganai, A. F., & Khursheed, F. (2019). Predicting next Word using RNN and LSTM cells: Statistical Language Modeling. In 2019 Fifth International Conference on Image Information Processing (ICIIP) (pp. 469-474). doi:10.1109/ICIIP47207.2019.8985885.\n",
        "\n",
        "[2] Weissenow, K., & Rost, B. (2025). Are protein language models the new universal key? Current Opinion in Structural Biology, 91, 102997.\n",
        "\n",
        "[3] Tufino, E. (2025). Exploring Large Language Models (LLMs) through interactive Python activities. arXiv preprint arXiv:2501.05577.\n",
        "\n",
        "[4] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. arXiv preprint arXiv:1301.3781.\n",
        "\n",
        "[5] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality. In Advances in Neural Information Processing Systems (NIPS), 26.\n",
        "\n",
        "[6] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention Is All You Need. In Advances in Neural Information Processing Systems (NIPS), 30.\n",
        "\n",
        "[7] Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805.\n"
      ],
      "metadata": {
        "id": "2251IC_fnBrE"
      }
    }
  ]
}